
Библиотеки:
pandas: Чтобы работать с таблицами данных.
scikit-learn: Чтобы делить данные на обучающую и тестовую выборки, масштабировать их и считать ошибки.
tensorflow: Чтобы создавать и обучать нейронные сети.
numpy: Чтобы работать с числами и массивами.
tgt: Чтобы читать файлы .TextGrid, где хранятся данные о фонемах.

Принцип работы:
Программа читает файлы .TextGrid, вытаскивает оттуда данные о фонемах (тип, ударение, позиция в слове и длительность).
Эти данные превращаются в таблицу, где все категории (тип фонемы, ударение и т.д.) кодируются числами (one-hot encoding).
Данные делятся на обучающую и тестовую выборки, а потом масштабируются.
Создаются три модели нейронных сетей:
Модель 1: Простая сеть с тремя слоями (128, 64, 32 нейрона) и регуляризацией.
Модель 2: Сеть с Dropout, чтобы не переобучалась.
Модель 3: Сеть побольше, с четырьмя слоями (256, 128, 64, 32 нейрона).
Модели обучаются на 100 эпохах, а потом тестируются.
В конце программа выводит, насколько хорошо модели справились (MAE, RMSE и процент правильно предсказанных фонем с отклонением не больше 10%).